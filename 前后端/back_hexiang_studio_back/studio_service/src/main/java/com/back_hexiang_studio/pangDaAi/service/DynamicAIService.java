package com.back_hexiang_studio.pangDaAi.service;

import com.back_hexiang_studio.pangDaAi.config.AIModelProperties;
import com.back_hexiang_studio.context.UserContextHolder;
import dev.langchain4j.model.chat.ChatModel;
import dev.langchain4j.model.chat.StreamingChatModel;
import dev.langchain4j.model.openai.OpenAiChatModel;
import dev.langchain4j.model.openai.OpenAiStreamingChatModel;
import jakarta.annotation.PostConstruct;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;


import java.time.Duration;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * åŠ¨æ€AIæœåŠ¡
 * æ ¹æ®æ™ºèƒ½è·¯ç”±é€‰æ‹©çš„æ¨¡å‹åŠ¨æ€åˆ›å»ºå’Œè°ƒç”¨AIæœåŠ¡
 */
@Service
@Slf4j
public class DynamicAIService {

    @Autowired
    private ModelRouterService modelRouterService;
    
    @Autowired
    private AIModelProperties aiModelProperties;
    
    // æ¨¡å‹å®ä¾‹ç¼“å­˜ï¼Œé¿å…é‡å¤åˆ›å»º
    private final Map<String, ChatModel> chatModelCache = new ConcurrentHashMap<>();
    private final Map<String, StreamingChatModel> streamingChatModelCache = new ConcurrentHashMap<>();
    
    @PostConstruct
    public void init() {
        log.info("  DynamicAIService æ­£åœ¨åˆå§‹åŒ–...");
        // å»¶è¿Ÿé¢„çƒ­ï¼Œé¿å…å¯åŠ¨é˜»å¡
        new Thread(() -> {
            try {
                Thread.sleep(5000); // ç­‰å¾…5ç§’åå¼€å§‹é¢„çƒ­
                warmupModels();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                log.warn("æ¨¡å‹é¢„çƒ­çº¿ç¨‹è¢«ä¸­æ–­");
            }
        }).start();
        log.info("  DynamicAIService åˆå§‹åŒ–å®Œæˆ");
    }
    
    /**
     * è·å–åŠ¨æ€é€‰æ‹©çš„èŠå¤©æ¨¡å‹
     */
    public ChatModel getChatModel(String userMessage, Long userId, String sessionId) {
        // ä½¿ç”¨æ™ºèƒ½è·¯ç”±é€‰æ‹©æ¨¡å‹
        ModelRouterService.AIModel selectedModel = modelRouterService.selectModel(userMessage, userId, sessionId);
        String modelName = selectedModel.getModelName();
        
        // ä»ç¼“å­˜è·å–æˆ–åˆ›å»ºæ–°å®ä¾‹
        return chatModelCache.computeIfAbsent(modelName, this::createChatModel);
    }
    
    /**
     * è·å–åŠ¨æ€é€‰æ‹©çš„æµå¼èŠå¤©æ¨¡å‹
     */
    public StreamingChatModel getStreamingChatModel(String userMessage, Long userId, String sessionId) {
        // ä½¿ç”¨æ™ºèƒ½è·¯ç”±é€‰æ‹©æ¨¡å‹
        ModelRouterService.AIModel selectedModel = modelRouterService.selectModel(userMessage, userId, sessionId);
        String modelName = selectedModel.getModelName();
        
        log.info("  åŠ¨æ€é€‰æ‹©æ¨¡å‹: {} ({})", modelName, selectedModel.getDescription());
        
        // ä»ç¼“å­˜è·å–æˆ–åˆ›å»ºæ–°å®ä¾‹
        return streamingChatModelCache.computeIfAbsent(modelName, this::createStreamingChatModel);
    }
    
    /**
     * æ ¹æ®æŒ‡å®šæ¨¡å‹åè·å–èŠå¤©æ¨¡å‹
     */
    public ChatModel getChatModelByName(String modelName) {
        return chatModelCache.computeIfAbsent(modelName, this::createChatModel);
    }
    
    /**
     * æ ¹æ®æŒ‡å®šæ¨¡å‹åè·å–æµå¼èŠå¤©æ¨¡å‹
     */
    public StreamingChatModel getStreamingChatModelByName(String modelName) {
        return streamingChatModelCache.computeIfAbsent(modelName, this::createStreamingChatModel);
    }
    
    /**
     * åˆ›å»ºèŠå¤©æ¨¡å‹å®ä¾‹
     */
    private ChatModel createChatModel(String modelName) {
        try {
            log.debug("ğŸ”§ åˆ›å»ºèŠå¤©æ¨¡å‹: {}", modelName);
            
            AIModelProperties.ModelConfig config = aiModelProperties.getModelConfig(modelName);
            int maxTokens = config != null && config.getMaxTokens() != null ? config.getMaxTokens() : 4000;
            
            return OpenAiChatModel.builder()
                    .apiKey(aiModelProperties.getApiKey())
                    .baseUrl(aiModelProperties.getBaseUrl())
                    .modelName(modelName)
                    .temperature(0.8)
                    .maxTokens(maxTokens)
                    .timeout(Duration.ofSeconds(180))
                    .logRequests(true)
                    .logResponses(true)
                    .build();
                    
        } catch (Exception e) {
            log.error("  åˆ›å»ºèŠå¤©æ¨¡å‹å¤±è´¥: {}, ä½¿ç”¨é»˜è®¤æ¨¡å‹", e.getMessage());
            // å›é€€åˆ°é»˜è®¤æ¨¡å‹
            return OpenAiChatModel.builder()
                    .apiKey(aiModelProperties.getApiKey())
                    .baseUrl(aiModelProperties.getBaseUrl())
                    .modelName("qwen-plus")
                    .temperature(0.8)
                    .maxTokens(4000)
                    .timeout(Duration.ofSeconds(180))
                    .build();
        }
    }
    
    /**
     * åˆ›å»ºæµå¼èŠå¤©æ¨¡å‹å®ä¾‹
     */
    private StreamingChatModel createStreamingChatModel(String modelName) {
        try {
            log.debug("ğŸ”§ åˆ›å»ºæµå¼èŠå¤©æ¨¡å‹: {}", modelName);
            
            AIModelProperties.ModelConfig config = aiModelProperties.getModelConfig(modelName);
            int maxTokens = config != null && config.getMaxTokens() != null ? config.getMaxTokens() : 4000;
            
            return OpenAiStreamingChatModel.builder()
                    .apiKey(aiModelProperties.getApiKey())
                    .baseUrl(aiModelProperties.getBaseUrl())
                    .modelName(modelName)
                    .temperature(0.8)
                    .maxTokens(maxTokens)
                    .timeout(Duration.ofSeconds(180))
                    .logRequests(true)
                    .logResponses(true)
                    .build();
                    
        } catch (Exception e) {
            log.error("  åˆ›å»ºæµå¼èŠå¤©æ¨¡å‹å¤±è´¥: {}, ä½¿ç”¨é»˜è®¤æ¨¡å‹", e.getMessage());
            // å›é€€åˆ°é»˜è®¤æ¨¡å‹
            return OpenAiStreamingChatModel.builder()
                    .apiKey(aiModelProperties.getApiKey())
                    .baseUrl(aiModelProperties.getBaseUrl())
                    .modelName("qwen-plus")
                    .temperature(0.8)
                    .maxTokens(4000)
                    .timeout(Duration.ofSeconds(180))
                    .build();
        }
    }
    
    /**
     * é¢„çƒ­å¸¸ç”¨æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
     */
    public void warmupModels() {
        log.info("  å¼€å§‹é¢„çƒ­å¸¸ç”¨æ¨¡å‹...");
        
        String[] commonModels = {"qwen-flash", "qwen-plus", "qwen-plus-latest", "qwen-max"};
        
        for (String modelName : commonModels) {
            try {
                if (aiModelProperties.isModelExists(modelName)) {
                    getChatModelByName(modelName);
                    getStreamingChatModelByName(modelName);
                    log.debug("  é¢„çƒ­æ¨¡å‹: {}", modelName);
                }
            } catch (Exception e) {
                log.warn("  é¢„çƒ­æ¨¡å‹å¤±è´¥: {} - {}", modelName, e.getMessage());
            }
        }
        
        log.info("  æ¨¡å‹é¢„çƒ­å®Œæˆ");
    }
    
    /**
     * æ¸…ç†æ¨¡å‹ç¼“å­˜
     */
    public void clearModelCache() {
        log.info("ğŸ§¹ æ¸…ç†æ¨¡å‹ç¼“å­˜...");
        chatModelCache.clear();
        streamingChatModelCache.clear();
        log.info("  æ¨¡å‹ç¼“å­˜æ¸…ç†å®Œæˆ");
    }
    
    /**
     * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
     */
    public String getCacheStats() {
        return String.format("èŠå¤©æ¨¡å‹ç¼“å­˜: %d, æµå¼æ¨¡å‹ç¼“å­˜: %d", 
            chatModelCache.size(), streamingChatModelCache.size());
    }
} 